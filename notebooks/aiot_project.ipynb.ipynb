{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"0733b351\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# AIoT Project\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"4455947d\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"# basic data engineering\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import scipy\\n\",\n",
    "    \"\\n\",\n",
    "    \"# plotting\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"# db\\n\",\n",
    "    \"import pymongo\\n\",\n",
    "    \"\\n\",\n",
    "    \"# configs & other\\n\",\n",
    "    \"import yaml\\n\",\n",
    "    \"from tqdm.notebook import tqdm_notebook\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"from time import time\\n\",\n",
    "    \"\\n\",\n",
    "    \"from psynlig import pca_explained_variance_bar\\n\",\n",
    "    \"\\n\",\n",
    "    \"# utils processing\\n\",\n",
    "    \"from utils import sliding_window_pd\\n\",\n",
    "    \"from utils import apply_filter\\n\",\n",
    "    \"from utils import filter_instances\\n\",\n",
    "    \"from utils import flatten_instances_df\\n\",\n",
    "    \"from utils import df_rebase\\n\",\n",
    "    \"from utils import rename_df_column_values\\n\",\n",
    "    \"\\n\",\n",
    "    \"# utils visualization\\n\",\n",
    "    \"from utils_visual import plot_instance_time_domain\\n\",\n",
    "    \"from utils_visual import plot_instance_3d\\n\",\n",
    "    \"from utils_visual import plot_np_instance\\n\",\n",
    "    \"from utils_visual import plot_heatmap\\n\",\n",
    "    \"from utils_visual import plot_scatter_pca\\n\",\n",
    "    \"\\n\",\n",
    "    \"%load_ext autoreload\\n\",\n",
    "    \"%autoreload 2\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"07adb678\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Start time of execution\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"717559c4\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"time_start = time()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"34b96e6f\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Load configuration\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"982eac13\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"config_path = os.path.join(os.getcwd(), \\\"config.yml\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"with open(config_path) as file:\\n\",\n",
    "    \"    config = yaml.load(file, Loader=yaml.FullLoader)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"bfce0bca\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"client = pymongo.MongoClient(config[\\\"client\\\"])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"dc950bbb\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"db = client[config[\\\"db\\\"]]\\n\",\n",
    "    \"coll = db[config[\\\"col\\\"]]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"2221ec1a\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"found_keys = coll.distinct(\\\"label\\\")\\n\",\n",
    "    \"print(\\\"Existing DB keys:\\\", found_keys)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"0c2b7f9c\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Apply filter\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"f73e077d\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Sample code to apply filters on data fetched from MongoDB\\n\",\n",
    "    \"data_cursor = coll.find()\\n\",\n",
    "    \"data_list = list(data_cursor)\\n\",\n",
    "    \"\\n\",\n",
    "    \"data_df_list = [pd.DataFrame(doc['data']) for doc in data_list]\\n\",\n",
    "    \"\\n\",\n",
    "    \"filtered_data = filter_instances(data_df_list, order=config['filter']['order'], wn=config['filter']['wn'], filter_type=config['filter']['type'])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"174424cd\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Transform the list of DataFrames to NumPy array\\n\",\n",
    "    \"\\n\",\n",
    "    \"Transform the list of DataFrames to NumPy array that contains the windows: (instances, x, y)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"741fe8b6\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Sample code to transform DataFrames to NumPy arrays\\n\",\n",
    "    \"np_data_list = [df.to_numpy() for df in filtered_data]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Assuming `sliding_window_pd` is already defined in utils, apply it here\\n\",\n",
    "    \"windows_list = [sliding_window_pd(df, ws=config['sliding_window']['ws'], overlap=config['sliding_window']['overlap']) for df in np_data_list]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Flatten the list of lists\\n\",\n",
    "    \"windows = [window for sublist in windows_list for window in sublist]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"9587c7d9\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Flatten the 2D window instances\\n\",\n",
    "    \"\\n\",\n",
    "    \"Flatten the X NumPy array that contains the 2D window instances\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"c49d38ed\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Sample code to flatten the window instances\\n\",\n",
    "    \"X = flatten_instances_df(windows)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"41620e98\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Train/Test split\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"1d592023\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.model_selection import train_test_split\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"b2b23d31\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Sample labels\\n\",\n",
    "    \"y = [doc['label'] for doc in data_list]\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True, random_state=42)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"a3b6aded\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Scaling\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"b12737cf\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.preprocessing import StandardScaler, MinMaxScaler\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"7d3d85a8\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Sample code for scaling\\n\",\n",
    "    \"scaler = StandardScaler()\\n\",\n",
    "    \"X_train_scaled = scaler.fit_transform(X_train)\\n\",\n",
    "    \"X_test_scaled = scaler.transform(X_test)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"bb41accf\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Dimensionality Reduction with PCA using the 1D (flattened) data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"c0c8c60a\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# add transformers\\n\",\n",
    "    \"from sklearn.decomposition import PCA\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"754f3a1b\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# PCA with 2 components\\n\",\n",
    "    \"pca = PCA(n_components=2)\\n\",\n",
    "    \"X_train_pca = pca.fit_transform(X_train_scaled)\\n\",\n",
    "    \"X_test_pca = pca.transform(X_test_scaled)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"8dd95258\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### PCA with 2 Components\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"4d8c1252\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"pca2d = PCA(n_components=2)\\n\",\n",
    "    \"pca2d.fit(X_train_scaled)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"1fd25884\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"X_train_2d = pca2d.transform(X_train_scaled)\\n\",\n",
    "    \"X_test_2d = pca2d.transform(X_test_scaled)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"1bc0ea67\",\n",
    "   \"metadata\": {\n",
    "    \"scrolled\": false\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"pca_explained_variance_bar(pca2d, alpha=0.8)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"ee7b3f0f\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"plot_scatter_pca(X_train_2d, y_train, title='PCA 2D Scatter Plot')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"91e107a4\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### PCA with 3 Components\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"2f59fb62\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"pca3d = PCA(n_components=3)\\n\",\n",
    "    \"pca3d.fit(X_train_scaled)\\n\",\n",
    "    \"X_train_3d = pca3d.transform(X_train_scaled)\\n\",\n",
    "    \"X_test_3d = pca3d.transform(X_test_scaled)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plot_instance_3d(X_train_3d, y_train)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"87e8d62f\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### PCA with X% of the variance of the dataset, for training the statistical AI Models\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"743bcd58\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"pca_var = PCA(n_components=0.95)  # Adjust the variance percentage as needed\\n\",\n",
    "    \"X_train_var = pca_var.fit_transform(X_train_scaled)\\n\",\n",
    "    \"X_test_var = pca_var.transform(X_test_scaled)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"de03fd48\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Classifier - Statistical Learning\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"789ce0a8\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Apply simple classifier\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"8846c809\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.svm import SVC\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestClassifier\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"c599deb1\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Initialize and train the SVC classifier\\n\",\n",
    "    \"svc = SVC(kernel='rbf', C=config['classifier']['SVC']['C'], gamma=config['classifier']['SVC']['gamma'])\\n\",\n",
    "    \"svc.fit(X_train_var, y_train)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"e2b4b498\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Evaluate simple classifier\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"ce02a18e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"11536a59\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate the classifier\\n\",\n",
    "    \"y_pred = svc.predict(X_test_var)\\n\",\n",
    "    \"cm = confusion_matrix(y_test, y_pred)\\n\",\n",
    "    \"disp = ConfusionMatrixDisplay(confusion_matrix=cm)\\n\",\n",
    "    \"disp.plot()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(classification_report(y_test, y_pred))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"ee969415\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Apply optimization with Grid Search and Cross-validation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"e9a3c651\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from sklearn.model_selection import GridSearchCV\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"ba17bf58\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define parameter grid\\n\",\n",
    "    \"param_grid = config['fine_tune']['param_grid']\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize GridSearchCV\\n\",\n",
    "    \"grid_search = GridSearchCV(estimator=SVC(), param_grid=param_grid, cv=config['fine_tune']['cv'], verbose=config['fine_tune']['verbose'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Fit the model\\n\",\n",
    "    \"grid_search.fit(X_train_var, y_train)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"0b1db5c5\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Evaluate optimized classifier\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"9e11ff71\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate the optimized classifier\\n\",\n",
    "    \"best_svc = grid_search.best_estimator_\\n\",\n",
    "    \"y_pred_optimized = best_svc.predict(X_test_var)\\n\",\n",
    "    \"cm_optimized = confusion_matrix(y_test, y_pred_optimized)\\n\",\n",
    "    \"disp_optimized = ConfusionMatrixDisplay(confusion_matrix=cm_optimized)\\n\",\n",
    "    \"disp_optimized.plot()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(classification_report(y_test, y_pred_optimized))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"95ada6c9\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Classifier - Neural Network\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"63cd8abe\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"from tensorflow.keras import Sequential\\n\",\n",
    "    \"from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Dropout, Flatten\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"983c3269\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"input_data_shape = X_train_2d[0].shape\\n\",\n",
    "    \"print(\\\"Type of the input shape object:\\\", type(input_data_shape))\\n\",\n",
    "    \"X_train_2d[0].shape\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"44bb9bab\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"y_np_array = np.array(y)\\n\",\n",
    "    \"n_outputs = len(np.unique(y_np_array))\\n\",\n",
    "    \"print(\\\"Number of outputs (classes) the model to predict:\\\", n_outputs)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"85b5be53\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Create the Neural Network (NN) Architecture and instantiate the model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"d2ca897e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model = Sequential()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add layers to the model\\n\",\n",
    "    \"model.add(Dense(64, activation='relu', input_shape=input_data_shape))\\n\",\n",
    "    \"model.add(Dropout(0.5))\\n\",\n",
    "    \"model.add(Dense(32, activation='relu'))\\n\",\n",
    "    \"model.add(Dense(n_outputs, activation='softmax'))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"5d086695\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Plot the Architecture of the TensorFlow model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"ce534b3e\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"tf.keras.utils.plot_model(model, show_shapes=True)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"cbb3c78a\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"Plot the summary of the TensorFlow model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"10a1370a\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"5ffb0f58\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Build the NN model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"62ec9310\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"31a646d6\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from utils import encode_labels\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"7f39477f\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Encode labels\\n\",\n",
    "    \"y_train_encoded = encode_labels(y_train)\\n\",\n",
    "    \"y_test_encoded = encode_labels(y_test)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"105b799d\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Train the NN model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"595a3664\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"history = model.fit(X_train_2d, y_train_encoded, epochs=config['fit']['epochs'], batch_size=config['fit']['batch'], validation_split=0.2, verbose=2)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"ee61e2f4\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Evaluate the model on the test data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"ddec8b5b\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"test_loss, test_acc = model.evaluate(X_test_2d, y_test_encoded)\\n\",\n",
    "    \"print(f\\\"Test accuracy: {test_acc:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"46cf5b35\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Plot and interpret the learning curves: Loss and Accuracy based on the training and validation sets\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"df775152\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"plt.figure(figsize=(12, 4))\\n\",\n",
    "    \"plt.subplot(1, 2, 1)\\n\",\n",
    "    \"plt.plot(history.history['loss'], label='Train Loss')\\n\",\n",
    "    \"plt.plot(history.history['val_loss'], label='Val Loss')\\n\",\n",
    "    \"plt.xlabel('Epochs')\\n\",\n",
    "    \"plt.ylabel('Loss')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.subplot(1, 2, 2)\\n\",\n",
    "    \"plt.plot(history.history['accuracy'], label='Train Accuracy')\\n\",\n",
    "    \"plt.plot(history.history['val_accuracy'], label='Val Accuracy')\\n\",\n",
    "    \"plt.xlabel('Epochs')\\n\",\n",
    "    \"plt.ylabel('Accuracy')\\n\",\n",
    "    \"plt.legend()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"id\": \"a0e06c98\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# End time of execution\\n\",\n",
    "    \"time_end = time()\\n\",\n",
    "    \"print(f\\\"Total execution time: {time_end - time_start:.2f} seconds\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3 (ipykernel)\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.16\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
